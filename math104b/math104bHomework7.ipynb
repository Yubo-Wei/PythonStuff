{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the conjugate gradient method to find an approximation of the solution of boundary value problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve boundary value problem\n",
    "# input: N \n",
    "# output: matrix \n",
    "# yubowei June2,2021\n",
    "\n",
    "def bvp(N):\n",
    "    x = np.linspace(0,1, N + 1) # the beam\n",
    "    h = 1/N # grid size\n",
    "    A = np.zeros((N-1,N-1))\n",
    "    for i in range(N - 1):\n",
    "        A[i][i] = 2+(h**2)*(np.pi**2) # diagonal form \n",
    "        if i > 0:\n",
    "            A[i][i-1] = -1\n",
    "            A[i-1][i] = -1\n",
    "    m = 1/2/(h**2)/(np.pi**2)*A\n",
    "    return m\n",
    "\n",
    "# Conjugate gradient method\n",
    "# input: N\n",
    "# output: x_bar\n",
    "\n",
    "def Conjugate_gradient(N):\n",
    "    x = np.zeros(N-1)\n",
    "    A = bvp(N)\n",
    "    b = np.sin(np.pi*np.linspace(0,1,N+1)[1:-1])\n",
    "    r = b - np.matmul(A,x)\n",
    "    v = r\n",
    "    k = 0\n",
    "    while numpy.linalg.norm(r) > N**-2:\n",
    "        t = np.dot(r,r)/np.dot(v, np.matmul(A,v))\n",
    "        x += t*v\n",
    "        r_k = r\n",
    "        r -= t*np.matmul(A,v)\n",
    "        s = np.dot(r,r)/np.dot(r_k,r_k)\n",
    "        v *= s\n",
    "        v += r\n",
    "        k += 1\n",
    "    print('required number of iterations : %i'%(k) )\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required number of iterations : 1\n",
      "required number of iterations : 1\n",
      "required number of iterations : 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0008224940857848943, 0.00029078839973917253, 0.00010280859065402574]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = [50,100,200]\n",
    "X = [np.linspace(0,1,N + 1) for N in n]\n",
    "u = [np.sin(np.pi*y) for y in X]\n",
    "x_bar = [np.concatenate([[0],Conjugate_gradient(N),[0]]) for N in n]\n",
    "errors = []\n",
    "\n",
    "for i in range(len(n)):\n",
    "    errors.append(numpy.linalg.norm(u[i]-x_bar[i]))\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.828496895070931"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0008224940857848943/0.00029078839973917253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8284445676114904"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.00029078839973917253/0.00010280859065402574\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 iteration is needed for a good approximation. \n",
    "The tolerance is $h^2$.\n",
    "We expect error to becomes four times smaller when doubling the value of N. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jacobi's method \n",
    "# INPUT: N\n",
    "# OUTPUT: x_bar\n",
    "\n",
    "def jacobi(N):\n",
    "    A = bvp(N)\n",
    "    x = np.zeros(N-1)\n",
    "    b = np.sin(np.pi*np.linspace(0,1,N+1)[1:-1])\n",
    "    r = b - np.matmul(A,x)\n",
    "    k = 0\n",
    "    while numpy.linalg.norm(r) > N**-2 and k < 100000:\n",
    "        x[0] = (b[0] - A[0,1]*x[1])/A[0,0]\n",
    "        x[-1] = (b[-1] - A[-1,-2]*x[-2])/A[-1,-1]\n",
    "        for i in range(1, len(x) - 1):\n",
    "            x[i] = (b[i]-A[i,i-1]*x[i-1]-A[i,i+1]*x[i+1])/A[i,i]\n",
    "        k += 1\n",
    "        r = b - np.matmul(A,x)\n",
    "    print('required number of iterations : %i'%(k) )\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required number of iterations : 1196\n",
      "required number of iterations : 5659\n",
      "required number of iterations : 26141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00042464748248324336, 0.00019107180583290687, 7.78214272862631e-05]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = [50,100,200]\n",
    "X = [np.linspace(0,1,N + 1) for N in n]\n",
    "u = [np.sin(np.pi*y) for y in X]\n",
    "x_bar = [np.concatenate([[0],jacobi(N),[0]]) for N in n]\n",
    "errors = []\n",
    "\n",
    "for i in range(len(n)):\n",
    "    errors.append(numpy.linalg.norm(u[i]-x_bar[i]))\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.222449725809361"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.00042464748248324336/0.00019107180583290687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4552595923235465"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.00019107180583290687/7.78214272862631e-05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the conjugate gradient method is better.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
